# Dataflow

Dataflow es un Google Cloud servicio que proporciona procesamiento unificado de datos por lotes y de transmisión a gran escala. Usa Dataflow para crear canalizaciones de datos en las que se lean una o más fuentes, se transformen los datos y se escriban en un destino.

Entre los casos prácticos típicos de Dataflow, se incluyen los siguientes:

- Transferencia de datos: Transferencia o replicación de datos entre subsistemas.
- Flujos de trabajo [ETL](https://cloud.google.com/learn/what-is-etl?hl=es-419) (extracción, transformación y carga) que transfieren datos a un almacén de datos, como BigQuery.
- Potenciación de paneles de IE.
- Aplicación del AA en tiempo real a la transmisión de datos.
- Procesamiento de datos del sensor o registro a gran escala.

Dataflow usa un modelo de canalización de datos, en el que los datos se mueven a través de una serie de etapas. Las etapas pueden incluir la lectura de datos de una fuente, la transformación y la agregación de datos, y la escritura de los resultados en un destino.

Las canalizaciones pueden variar desde un procesamiento muy simple hasta uno más complejo. Por ejemplo, una canalización puede hacer lo siguiente:

- Mover los datos como están a un destino.
- Transformar los datos para que el sistema de destino pueda usarlos más.
- Agregar, procesar y enriquecer los datos para el análisis.
- Unir los datos con otros datos.